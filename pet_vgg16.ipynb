{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "048d6cb9-14c1-4e71-b4be-cfcf7ab4167a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/18/cf/f69dff972a748e08e1bf602ef94ea5c6d4dd2f41cea22c8ad67a607d8b41/torch-2.4.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torch-2.4.0-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
      "Collecting torchvision\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/6a/38/e8257ad99ea2ec30bbb4e6d9d81f3fe796e39046bb060d80569cbf6d83e5/torchvision-0.19.0-1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torchvision-0.19.0-1-cp311-cp311-win_amd64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\peter\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\peter\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\peter\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\peter\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\peter\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\peter\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\peter\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\peter\\anaconda3\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\peter\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\peter\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Using cached torch-2.4.0-cp311-cp311-win_amd64.whl (197.9 MB)\n",
      "Using cached torchvision-0.19.0-1-cp311-cp311-win_amd64.whl (1.3 MB)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-2.4.0 torchvision-0.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfbf905b-4de8-41ea-98bd-00d890537fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Angry', 'Other', 'Sad', 'happy']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 이미지 변환 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # VGG 모델의 입력 크기\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 데이터셋 로드 (경로 수정)\n",
    "train_dataset = ImageFolder(root='C://Users//peter//Desktop//pet//master//train', transform=transform)\n",
    "val_dataset = ImageFolder(root='C://Users//peter//Desktop//pet//master//valid', transform=transform)\n",
    "\n",
    "# 데이터로더 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 데이터셋 클래스 확인\n",
    "print(train_dataset.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252013cb-8a1c-42ab-bdaa-4f76df226c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.4847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 25.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  91%|████████████████████████████████████████████████████▌     | 29/32 [52:03<05:17, 105.70s/it, loss=1.28]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from tqdm import tqdm  # 진행 바 라이브러리\n",
    "\n",
    "# 이미지 변환 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # VGG 모델의 입력 크기\n",
    "    transforms.ToTensor(),  # 이미지를 텐서로 변환\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 정규화\n",
    "])\n",
    "\n",
    "# 데이터셋 로드 (경로 수정)\n",
    "train_dataset = ImageFolder(root='C://Users//peter//Desktop//pet//master//train', transform=transform)\n",
    "val_dataset = ImageFolder(root='C://Users//peter//Desktop//pet//master//valid', transform=transform)\n",
    "\n",
    "# 데이터로더 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# GPU 사용 여부 확인\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# VGG 모델 로드 및 수정\n",
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "model.classifier[6] = nn.Linear(4096, 4)  # 4개의 클래스 분류\n",
    "model = model.to(device)  # 모델을 GPU/CPU로 이동\n",
    "\n",
    "# 손실 함수 및 최적화기 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 학습 함수 (GPU 사용 추가)\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        # tqdm을 사용하여 진행 바 추가\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False)\n",
    "        for inputs, labels in train_loader_tqdm:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # 데이터를 GPU/CPU로 이동\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # 진행 바 설명 업데이트\n",
    "            train_loader_tqdm.set_postfix(loss=running_loss/len(train_loader))\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "        # 평가\n",
    "        evaluate_model(model, val_loader)\n",
    "\n",
    "# 모델 평가 함수 (GPU 사용 추가)\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        val_loader_tqdm = tqdm(val_loader, desc='Validation', leave=False)\n",
    "        for inputs, labels in val_loader_tqdm:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # 데이터를 GPU/CPU로 이동\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "# 모델 학습\n",
    "train_model(model, criterion, optimizer, train_loader, val_loader)\n",
    "\n",
    "# 모델 저장\n",
    "torch.save(model.state_dict(), 'pet_expression_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c8a22-08cb-4ccc-a2db-50ec4810a9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b25e545-a2e0-4942-99c4-a8018bd5abdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
