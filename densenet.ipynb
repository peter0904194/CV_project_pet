{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-08-03T06:04:44.053561Z","iopub.status.busy":"2024-08-03T06:04:44.053301Z","iopub.status.idle":"2024-08-03T06:05:00.134091Z","shell.execute_reply":"2024-08-03T06:05:00.133107Z","shell.execute_reply.started":"2024-08-03T06:04:44.053536Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.60.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n","Collecting keras<2.16,>=2.15.0 (from tensorflow)\n","  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.32.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n","Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: keras\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.4.1\n","    Uninstalling keras-3.4.1:\n","      Successfully uninstalled keras-3.4.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.15.0\n"]}],"source":["!pip install tensorflow"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-03T06:05:00.136656Z","iopub.status.busy":"2024-08-03T06:05:00.136194Z","iopub.status.idle":"2024-08-03T06:05:12.115968Z","shell.execute_reply":"2024-08-03T06:05:12.114982Z","shell.execute_reply.started":"2024-08-03T06:05:00.136617Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-08-03 06:05:01.958217: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-08-03 06:05:01.958314: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-08-03 06:05:02.104949: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"name":"stdout","output_type":"stream","text":["2.15.0\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-03T06:05:12.118657Z","iopub.status.busy":"2024-08-03T06:05:12.118016Z","iopub.status.idle":"2024-08-03T06:05:12.164111Z","shell.execute_reply":"2024-08-03T06:05:12.163217Z","shell.execute_reply.started":"2024-08-03T06:05:12.118623Z"},"trusted":true},"outputs":[],"source":["EPOCHS = 10\n","\n","## DenseUnit 구현\n","class DenseUnit(tf.keras.Model):\n","    def __init__(self, filter_out, kernel_size):\n","        super(DenseUnit, self).__init__()\n","        # batch normalization -> ReLu -> Conv Layer\n","        # 여기서 ReLu 같은 경우는 변수가 없는 Layer이므로 여기서 굳이 initialize 해주지 않는다. (call쪽에서 사용하면 되므로)\n","        # Pre-activation 구조는 똑같이 가져가되, concatenate 구조로 만들어주어야함에 주의하자!!\n","\n","        self.bn = tf.keras.layers.BatchNormalization()\n","        self.conv = tf.keras.layers.Conv2D(filter_out, kernel_size, padding='same')\n","        self.concat = tf.keras.layers.Concatenate()\n","\n","    def call(self, x, training=False, mask=None): # x : (Batch 갯수, Height, width, Channel_in)\n","        # training 꼭 잊어버리지 말자!!\n","        h = self.bn(x, training=training)\n","        h = tf.nn.relu(h)\n","        h = self.conv(h) # h : (Batch, height, width, filter_output) zero-padding을 했으므로 filter만 바뀜\n","        return self.concat([x, h]) # (Batch, height, width, (channel_in + filter_output))\n","\n","## DenseLayer 구현\n","class DenseLayer(tf.keras.Model):\n","    def __init__(self, num_unit, growth_rate, kernel_size):\n","        super(DenseLayer, self).__init__()\n","        self.sequence = list()\n","        for idx in range(num_unit):\n","            self.sequence.append(DenseUnit(growth_rate, kernel_size))\n","\n","    def call(self, x, training=False, mask=None):\n","        for unit in self.sequence:\n","            x = unit(x, training=training)\n","        return x\n","\n","## Transition Layer 구현\n","# Maxpooling을 해줄 때 필요함.\n","# 예를 들어, DenseLayer를 사용을 하게 되면, Growth_rate=32, num_unit=8인 경우에는, 32X8 만큼 channel의 수가 급격하게 증가하기 때문에 너무 커질 수 있다. 이럴 경우 이 Transition Layer를 통해 Pooling 전에 channel의 수를 조절해주기 위해 사용되는 것이다.\n","class TransitionLayer(tf.keras.Model):\n","    def __init__(self, filters, kernel_size):\n","        super(TransitionLayer, self).__init__()\n","        # transition을 할 경우에는 이렇게 convolution을 해서 단순히 filter 개수를 변경만 해준뒤\n","        # 그 다음에 Maxpooling을 해주는 식으로 구현이 된다.\n","        self.conv = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n","        self.pool = tf.keras.layers.MaxPool2D()\n","\n","    def call(self, x, training=False, mask=None):\n","        # 여기서는 Batch normalization이 없기 때문에 training을 안써줘도 된다.\n","        x = self.conv(x)\n","        return self.pool(x)\n","\n","## 모델 정의\n","class DenseNet(tf.keras.Model):\n","    def __init__(self):\n","        super(DenseNet, self).__init__()\n","        self.conv1 = tf.keras.layers.Conv2D(8, (3, 3), padding='same', activation='relu') # 28x28x8\n","\n","        # num_unit=2, growth_rate=4, kernel_size=(3,3)\n","        # num_unit은 ResNet과 동일\n","        self.dl1 = DenseLayer(2, 4, (3, 3)) # 28x28x(8+2*4)\n","        self.tr1 = TransitionLayer(16, (3, 3)) # 14x14x16\n","\n","        self.dl2 = DenseLayer(2, 8, (3, 3)) # 14x14x(16 + 2*8)\n","        self.tr2 = TransitionLayer(32, (3, 3)) # 7x7x32\n","\n","        self.dl3 = DenseLayer(2, 16, (3, 3)) # 7x7x(32+2*16)\n","\n","        self.flatten = tf.keras.layers.Flatten()\n","        self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n","        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')       \n","\n","    def call(self, x, training=False, mask=None):\n","        x = self.conv1(x)\n","\n","        x = self.dl1(x, training=training)\n","        x = self.tr1(x)\n","\n","        x = self.dl2(x, training=training)\n","        x = self.tr2(x)\n","\n","        x = self.dl3(x, training=training)\n","\n","        x = self.flatten(x)\n","        x = self.dense1(x)\n","        return self.dense2(x)\n","\n","\n","## 학습, 데스트 루프 정의\n","\n","# Implement training loop\n","@tf.function\n","def train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy):\n","    with tf.GradientTape() as tape:\n","        predictions = model(images, training=True)\n","        loss = loss_object(labels, predictions)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    train_loss(loss)\n","    train_accuracy(labels, predictions)\n","\n","# Implement algorithm test\n","@tf.function\n","def test_step(model, images, labels, loss_object, test_loss, test_accuracy):\n","    predictions = model(images, training=False)\n","\n","    t_loss = loss_object(labels, predictions)\n","    test_loss(t_loss)\n","    test_accuracy(labels, predictions)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T16:46:15.876462Z","iopub.status.busy":"2024-08-02T16:46:15.876173Z","iopub.status.idle":"2024-08-02T16:46:17.879752Z","shell.execute_reply":"2024-08-02T16:46:17.878728Z","shell.execute_reply.started":"2024-08-02T16:46:15.876439Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n"]}],"source":["## 데이터셋 준비\n","mnist = tf.keras.datasets.mnist\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","x_train = x_train[..., tf.newaxis].astype(np.float32)\n","x_test = x_test[..., tf.newaxis].astype(np.float32)\n","\n","train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n","test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-03T06:20:08.871442Z","iopub.status.busy":"2024-08-03T06:20:08.870735Z","iopub.status.idle":"2024-08-03T06:20:10.824009Z","shell.execute_reply":"2024-08-03T06:20:10.823235Z","shell.execute_reply.started":"2024-08-03T06:20:08.871409Z"},"trusted":true},"outputs":[],"source":["## 학습 환경 정의\n","# 모델 생성, 손실함수, 최적화 알고리즘, 평가지표 정의\n","\n","# 모델 생성\n","model = DenseNet()\n","\n","# 손실함수 정의 및 최적화 기법 정의\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n","optimizer = tf.keras.optimizers.Adam()\n","\n","# 평가지표 정의\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","\n","test_loss = tf.keras.metrics.Mean(name='test_loss')\n","test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-03T06:20:29.382319Z","iopub.status.busy":"2024-08-03T06:20:29.381626Z","iopub.status.idle":"2024-08-03T06:22:43.712692Z","shell.execute_reply":"2024-08-03T06:22:43.711737Z","shell.execute_reply.started":"2024-08-03T06:20:29.382291Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1722666035.187315     142 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 0.11722613126039505, Accuracy: 96.55166625976562, Test Loss: 0.055627528578042984, Test Accuracy: 98.3499984741211\n","Epoch 2, Loss: 0.08699080348014832, Accuracy: 97.4566650390625, Test Loss: 0.05324681103229523, Test Accuracy: 98.47999572753906\n","Epoch 3, Loss: 0.07333599776029587, Accuracy: 97.88166809082031, Test Loss: 0.053093694150447845, Test Accuracy: 98.4566650390625\n","Epoch 4, Loss: 0.06511535495519638, Accuracy: 98.1312484741211, Test Loss: 0.053559087216854095, Test Accuracy: 98.43999481201172\n","Epoch 5, Loss: 0.05910111963748932, Accuracy: 98.3169937133789, Test Loss: 0.05311901494860649, Test Accuracy: 98.52400207519531\n","Epoch 6, Loss: 0.05468367040157318, Accuracy: 98.4477767944336, Test Loss: 0.05416098237037659, Test Accuracy: 98.56832885742188\n","Epoch 7, Loss: 0.051100026816129684, Accuracy: 98.56071472167969, Test Loss: 0.054947707802057266, Test Accuracy: 98.5971450805664\n","Epoch 8, Loss: 0.04772491753101349, Accuracy: 98.66020965576172, Test Loss: 0.05793722718954086, Test Accuracy: 98.57749938964844\n","Epoch 9, Loss: 0.04554792866110802, Accuracy: 98.73074340820312, Test Loss: 0.05872904136776924, Test Accuracy: 98.59666442871094\n","Epoch 10, Loss: 0.04324238747358322, Accuracy: 98.7993392944336, Test Loss: 0.05975170060992241, Test Accuracy: 98.5790023803711\n"]}],"source":["## 학습 루프 동작\n","# 어떤 것은 DenseNet이 성능이 더 좋게 나오고 어떤 것은 ResNet이 더 좋게 나오기도 한다. 또한 parameter에 따라 다르다. Resnet은 좀 더 안정적이게 수렴하지만 Densenet은 좀 fluctuate하다는 점을 유의하자.\n","\n","for epoch in range(EPOCHS):\n","  for images, labels in train_ds:\n","    train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy)\n","\n","  for test_images, test_labels in test_ds:\n","    test_step(model, test_images, test_labels, loss_object, test_loss, test_accuracy)\n","\n","  template = \"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}\"\n","  print(template.format(epoch+1,\n","                        train_loss.result(),\n","                        train_accuracy.result() * 100,\n","                        test_loss.result(),\n","                        test_accuracy.result() * 100))\n","\n","#train_loss.reset_states()\n","#train_accuracy.reset_states()\n","#test_loss.reset_states()\n","#test_accuray.reset_states()"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-08-03T06:48:12.690350Z","iopub.status.busy":"2024-08-03T06:48:12.689690Z","iopub.status.idle":"2024-08-03T06:50:14.016246Z","shell.execute_reply":"2024-08-03T06:50:14.015348Z","shell.execute_reply.started":"2024-08-03T06:48:12.690320Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1660 images belonging to 5 classes.\n","Found 414 images belonging to 5 classes.\n","Number of classes: 5\n","Class names: ['Angry', 'Master Folder', 'Other', 'Sad', 'happy']\n","Number of training images: 1660\n","Number of validation images: 414\n","Epoch 1/10\n","51/51 [==============================] - 71s 153ms/step - loss: 1.6180 - accuracy: 0.4743 - val_loss: 1.4994 - val_accuracy: 0.5234\n","Epoch 2/10\n","51/51 [==============================] - 10s 94ms/step - loss: 1.4674 - accuracy: 0.4994 - val_loss: 1.3984 - val_accuracy: 0.5156\n","Epoch 3/10\n","51/51 [==============================] - 5s 92ms/step - loss: 1.3881 - accuracy: 0.5092 - val_loss: 1.3910 - val_accuracy: 0.5156\n","Epoch 4/10\n","51/51 [==============================] - 5s 90ms/step - loss: 1.3412 - accuracy: 0.5221 - val_loss: 1.4413 - val_accuracy: 0.5156\n","Epoch 5/10\n","51/51 [==============================] - 5s 92ms/step - loss: 1.3277 - accuracy: 0.5092 - val_loss: 1.3884 - val_accuracy: 0.5078\n","Epoch 6/10\n","51/51 [==============================] - 5s 92ms/step - loss: 1.3100 - accuracy: 0.5197 - val_loss: 1.5263 - val_accuracy: 0.5104\n","Epoch 7/10\n","51/51 [==============================] - 5s 93ms/step - loss: 1.3353 - accuracy: 0.4963 - val_loss: 1.4660 - val_accuracy: 0.5156\n","Epoch 8/10\n","51/51 [==============================] - 5s 92ms/step - loss: 1.2992 - accuracy: 0.5147 - val_loss: 1.3654 - val_accuracy: 0.5104\n","Epoch 9/10\n","51/51 [==============================] - 5s 96ms/step - loss: 1.2792 - accuracy: 0.5215 - val_loss: 1.4088 - val_accuracy: 0.5104\n","Epoch 10/10\n","51/51 [==============================] - 5s 89ms/step - loss: 1.2718 - accuracy: 0.4945 - val_loss: 1.3988 - val_accuracy: 0.4505\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x7aa216fb3640>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# 데이터셋 폴더 경로\n","dataset_dir = '/kaggle/input/pets-facial-expression-dataset/'\n","\n","# 데이터 변환 및 로드\n","datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2  # 20% 데이터를 검증용으로 사용\n",")\n","\n","# 학습 데이터 로드\n","train_generator = datagen.flow_from_directory(\n","    dataset_dir,\n","    target_size=(32, 32),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='training'\n",")\n","\n","# 검증 데이터 로드\n","validation_generator = datagen.flow_from_directory(\n","    dataset_dir,\n","    target_size=(32, 32),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='validation'\n",")\n","\n","# 클래스 이름 및 샘플 수 출력\n","print(f'Number of classes: {len(train_generator.class_indices)}')\n","print(f'Class names: {list(train_generator.class_indices.keys())}')\n","print(f'Number of training images: {train_generator.samples}')\n","print(f'Number of validation images: {validation_generator.samples}')\n","\n","# 입력 이미지를 3채널로 변환하는 사용자 정의 데이터 생성기\n","def custom_generator(generator):\n","    while True:\n","        batch_x, batch_y = next(generator)\n","        yield batch_x, batch_y"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-08-03T06:50:47.158488Z","iopub.status.busy":"2024-08-03T06:50:47.157581Z","iopub.status.idle":"2024-08-03T06:52:34.864732Z","shell.execute_reply":"2024-08-03T06:52:34.863469Z","shell.execute_reply.started":"2024-08-03T06:50:47.158449Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","51/51 [==============================] - 60s 139ms/step - loss: 1.6183 - accuracy: 0.4865 - val_loss: 1.4492 - val_accuracy: 0.5156\n","Epoch 2/10\n","51/51 [==============================] - 5s 96ms/step - loss: 1.4237 - accuracy: 0.5092 - val_loss: 1.4405 - val_accuracy: 0.5130\n","Epoch 3/10\n","51/51 [==============================] - 5s 93ms/step - loss: 1.4028 - accuracy: 0.5031 - val_loss: 1.4346 - val_accuracy: 0.5156\n","Epoch 4/10\n","51/51 [==============================] - 5s 96ms/step - loss: 1.3391 - accuracy: 0.5350 - val_loss: 1.4054 - val_accuracy: 0.5286\n","Epoch 5/10\n","51/51 [==============================] - 5s 96ms/step - loss: 1.3500 - accuracy: 0.4982 - val_loss: 1.4161 - val_accuracy: 0.5208\n","Epoch 6/10\n","51/51 [==============================] - 5s 103ms/step - loss: 1.3468 - accuracy: 0.5092 - val_loss: 1.4113 - val_accuracy: 0.5104\n","Epoch 7/10\n","51/51 [==============================] - 5s 99ms/step - loss: 1.3193 - accuracy: 0.5227 - val_loss: 1.4225 - val_accuracy: 0.5156\n","Epoch 8/10\n","51/51 [==============================] - 5s 99ms/step - loss: 1.3300 - accuracy: 0.5172 - val_loss: 1.3528 - val_accuracy: 0.5078\n","Epoch 9/10\n","51/51 [==============================] - 5s 97ms/step - loss: 1.3127 - accuracy: 0.5031 - val_loss: 1.3549 - val_accuracy: 0.5104\n","Epoch 10/10\n","51/51 [==============================] - 5s 99ms/step - loss: 1.2962 - accuracy: 0.5147 - val_loss: 1.2984 - val_accuracy: 0.5286\n"]},{"ename":"ValueError","evalue":"in user code:\n\n    File \"/tmp/ipykernel_34/2489616372.py\", line 93, in train_step  *\n        predictions = model(images, training=True)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_1\" is incompatible with the layer: expected shape=(None, 32, 32, 3), found shape=(32, 28, 28, 1)\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m     29\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_ds:\n\u001b[0;32m---> 30\u001b[0m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_accuracy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m test_images, test_labels \u001b[38;5;129;01min\u001b[39;00m test_ds:\n\u001b[1;32m     33\u001b[0m     test_step(model, test_images, test_labels, loss_object, test_loss, test_accuracy)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/tmp/__autograph_generated_filegh4fiaay.py:9\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(model, images, labels, loss_object, optimizer, train_loss, train_accuracy)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mFunctionScope(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_step\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfscope\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mConversionOptions(recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, user_requested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, optional_features\u001b[38;5;241m=\u001b[39m(), internal_convert_user_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)) \u001b[38;5;28;01mas\u001b[39;00m fscope:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m----> 9\u001b[0m         predictions \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m         loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(loss_object), (ag__\u001b[38;5;241m.\u001b[39mld(labels), ag__\u001b[38;5;241m.\u001b[39mld(predictions)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(loss), ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/input_spec.py:298\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m--> 298\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    299\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    301\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_shape(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m         )\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_34/2489616372.py\", line 93, in train_step  *\n        predictions = model(images, training=True)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_1\" is incompatible with the layer: expected shape=(None, 32, 32, 3), found shape=(32, 28, 28, 1)\n"]}],"source":["# 모델 정의 및 컴파일\n","from tensorflow.keras.applications import DenseNet121\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","\n","base_model = DenseNet121(weights=None, include_top=False, input_shape=(32, 32, 3))\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(1024, activation='relu')(x)\n","predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)  # 클래스 수를 동적으로 설정\n","\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# 모델 학습\n","model.fit(\n","    custom_generator(train_generator),\n","    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n","    validation_data=custom_generator(validation_generator),\n","    validation_steps=validation_generator.samples // validation_generator.batch_size,\n","    epochs=10\n",")\n","\n","## 학습 루프 동작\n","# 어떤 것은 DenseNet이 성능이 더 좋게 나오고 어떤 것은 ResNet이 더 좋게 나오기도 한다. 또한 parameter에 따라 다르다. Resnet은 좀 더 안정적이게 수렴하지만 Densenet은 좀 fluctuate하다는 점을 유의하자.\n","\n","for epoch in range(EPOCHS):\n","  for images, labels in train_ds:\n","    train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy)\n","\n","  for test_images, test_labels in test_ds:\n","    test_step(model, test_images, test_labels, loss_object, test_loss, test_accuracy)\n","\n","  template = \"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}\"\n","  print(template.format(epoch+1,\n","                        train_loss.result(),\n","                        train_accuracy.result() * 100,\n","                        test_loss.result(),\n","                        test_accuracy.result() * 100))\n","\n","#train_loss.reset_states()\n","#train_accuracy.reset_states()\n","#test_loss.reset_states()\n","#test_accuray.reset_states()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":3546787,"sourceId":6665954,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
